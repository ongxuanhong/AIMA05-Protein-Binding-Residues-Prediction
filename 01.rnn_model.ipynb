{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/y2/hzjfncr92llg100m08nwxmhc0000gn/T/ipykernel_1621/3044583022.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/opt/homebrew/anaconda3/envs/AIMA05/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import ast\n",
    "from Bio import SeqIO\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1169, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>binding_sites</th>\n",
       "      <th>num_residues</th>\n",
       "      <th>target</th>\n",
       "      <th>sites_pos_min</th>\n",
       "      <th>sites_pos_max</th>\n",
       "      <th>sites_pos_mean</th>\n",
       "      <th>sites_pos_std</th>\n",
       "      <th>sites_pos_median</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q5LL55</td>\n",
       "      <td>MSETWLPTLVTATPQEGFDLAVKLSRIAVKKTQPDAQVRDTLRAVY...</td>\n",
       "      <td>76</td>\n",
       "      <td>[53, 46, 32, 42, 25, 60, 56, 43, 57, 31, 54, 2...</td>\n",
       "      <td>17</td>\n",
       "      <td>small</td>\n",
       "      <td>22</td>\n",
       "      <td>60</td>\n",
       "      <td>40.529412</td>\n",
       "      <td>11.887302</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H9L4N9</td>\n",
       "      <td>MQINIQGHHIDLTDSMQDYVHSKFDKLERFFDHINHVQVILRVEKL...</td>\n",
       "      <td>95</td>\n",
       "      <td>[51, 62, 42, 60, 55, 64]</td>\n",
       "      <td>6</td>\n",
       "      <td>metal</td>\n",
       "      <td>42</td>\n",
       "      <td>64</td>\n",
       "      <td>55.666667</td>\n",
       "      <td>7.498148</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O34738</td>\n",
       "      <td>MKSWKVKEIVIMSVISIVFAVVYLLFTHFGNVLAGMFGPIAYEPIY...</td>\n",
       "      <td>199</td>\n",
       "      <td>[100, 46, 104, 88, 63, 42, 77, 135, 91, 108, 2...</td>\n",
       "      <td>22</td>\n",
       "      <td>small</td>\n",
       "      <td>23</td>\n",
       "      <td>135</td>\n",
       "      <td>86.227273</td>\n",
       "      <td>34.010602</td>\n",
       "      <td>95</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P39579</td>\n",
       "      <td>MDFKQEVLDVLAEVCQDDIVKENPDIEIFEEGLLDSFGTVELLLAI...</td>\n",
       "      <td>78</td>\n",
       "      <td>[37, 36, 40, 61]</td>\n",
       "      <td>4</td>\n",
       "      <td>small</td>\n",
       "      <td>36</td>\n",
       "      <td>61</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>10.210289</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P01887</td>\n",
       "      <td>MARSVTLVFLVLVSLTGLYAIQKTPQIQVYSRHPPENGKPNILNCY...</td>\n",
       "      <td>119</td>\n",
       "      <td>[83, 77]</td>\n",
       "      <td>2</td>\n",
       "      <td>metal</td>\n",
       "      <td>77</td>\n",
       "      <td>83</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>83</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                           sequence  seq_len  \\\n",
       "0  Q5LL55  MSETWLPTLVTATPQEGFDLAVKLSRIAVKKTQPDAQVRDTLRAVY...       76   \n",
       "1  H9L4N9  MQINIQGHHIDLTDSMQDYVHSKFDKLERFFDHINHVQVILRVEKL...       95   \n",
       "2  O34738  MKSWKVKEIVIMSVISIVFAVVYLLFTHFGNVLAGMFGPIAYEPIY...      199   \n",
       "3  P39579  MDFKQEVLDVLAEVCQDDIVKENPDIEIFEEGLLDSFGTVELLLAI...       78   \n",
       "4  P01887  MARSVTLVFLVLVSLTGLYAIQKTPQIQVYSRHPPENGKPNILNCY...      119   \n",
       "\n",
       "                                       binding_sites  num_residues target  \\\n",
       "0  [53, 46, 32, 42, 25, 60, 56, 43, 57, 31, 54, 2...            17  small   \n",
       "1                           [51, 62, 42, 60, 55, 64]             6  metal   \n",
       "2  [100, 46, 104, 88, 63, 42, 77, 135, 91, 108, 2...            22  small   \n",
       "3                                   [37, 36, 40, 61]             4  small   \n",
       "4                                           [83, 77]             2  metal   \n",
       "\n",
       "   sites_pos_min  sites_pos_max  sites_pos_mean  sites_pos_std  \\\n",
       "0             22             60       40.529412      11.887302   \n",
       "1             42             64       55.666667       7.498148   \n",
       "2             23            135       86.227273      34.010602   \n",
       "3             36             61       43.500000      10.210289   \n",
       "4             77             83       80.000000       3.000000   \n",
       "\n",
       "   sites_pos_median  is_duplicate  fold  \n",
       "0                40         False     1  \n",
       "1                60         False     1  \n",
       "2                95         False     1  \n",
       "3                40         False     1  \n",
       "4                83          True     1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_proteins = pd.read_parquet(\"data_preparation/all_proteins_with_fold.parquet\")\n",
    "print(df_proteins.shape)\n",
    "display(df_proteins.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence: MLAIVAYIGFLALFTGIAAGLLFGLRSAKIL\n",
      "Binding sites: [ 8 12 16  3 23 15  4  7]\n"
     ]
    }
   ],
   "source": [
    "# check sample in the dataset with min sequence length\n",
    "min_seq_len = df_proteins[\"seq_len\"].min()\n",
    "min_idx = df_proteins[df_proteins[\"seq_len\"] == min_seq_len].index[0]\n",
    "\n",
    "# print sample sequence and binding sites\n",
    "print(\"Sequence:\", df_proteins[\"sequence\"].loc[min_idx])\n",
    "print(\"Binding sites:\", df_proteins[\"binding_sites\"].loc[min_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min sequence length: 31\n",
      "Max sequence length: 556\n"
     ]
    }
   ],
   "source": [
    "# print min, max sequence length\n",
    "min_seq_len = df_proteins[\"seq_len\"].min()\n",
    "max_seq_len = df_proteins[\"seq_len\"].max()\n",
    "print(\"Min sequence length:\", min_seq_len)\n",
    "print(\"Max sequence length:\", max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.Create vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def antigen_tokenizer(antigen):\n",
    "    return [aa for aa in antigen]\n",
    "\n",
    "\n",
    "def create_vocab(data, vocab_size):\n",
    "    # Create a function to yield list of tokens\n",
    "    def yield_tokens(antigens):\n",
    "        for seq in antigens:\n",
    "            yield antigen_tokenizer(seq)\n",
    "\n",
    "    # Create vocabulary\n",
    "    vocab = build_vocab_from_iterator(\n",
    "        yield_tokens(data), max_tokens=vocab_size, specials=[\"<pad>\", \"<unk>\"]\n",
    "    )\n",
    "    vocab.set_default_index(vocab[\"<unk>\"])\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " '<unk>': 1,\n",
       " 'L': 2,\n",
       " 'A': 3,\n",
       " 'E': 4,\n",
       " 'G': 5,\n",
       " 'V': 6,\n",
       " 'S': 7,\n",
       " 'K': 8,\n",
       " 'D': 9,\n",
       " 'I': 10,\n",
       " 'T': 11,\n",
       " 'R': 12,\n",
       " 'P': 13,\n",
       " 'N': 14,\n",
       " 'F': 15,\n",
       " 'Q': 16,\n",
       " 'Y': 17,\n",
       " 'M': 18,\n",
       " 'H': 19,\n",
       " 'C': 20,\n",
       " 'W': 21,\n",
       " 'U': 22,\n",
       " 'X': 23}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = create_vocab(df_proteins[\"sequence\"], 30)\n",
    "dict(sorted(vocab.get_stoi().items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpitopeDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_amino_acids(antigen, vocab, max_len):\n",
    "    encoded_seq = vocab(antigen_tokenizer(antigen))\n",
    "    num_pads = max_len - len(antigen)\n",
    "    encoded_seq += [vocab[\"<pad>\"]] * num_pads\n",
    "    return encoded_seq\n",
    "\n",
    "\n",
    "def prepare_dataset(df, vocab, max_len):\n",
    "    # encoding aminio acids\n",
    "    X = [vectorize_amino_acids(seq, vocab, max_len) for seq in df[\"sequence\"]]\n",
    "\n",
    "    # residues to one-hot\n",
    "    n_seq = df.shape[0]\n",
    "    Y = np.zeros((n_seq, max_len))\n",
    "    for i, labels in enumerate(df[\"binding_sites\"]):\n",
    "        for pos in labels:\n",
    "            # -1 because the first position in array is 0\n",
    "            Y[i, pos - 1] = 1\n",
    "\n",
    "    return EpitopeDataset(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: 234 samples\n",
      "Fold 1: 229 samples\n",
      "Fold 2: 232 samples\n",
      "Fold 3: 236 samples\n",
      "Fold 4: 238 samples\n"
     ]
    }
   ],
   "source": [
    "# split into different folds based on column \"fold\"\n",
    "n_folds = 5\n",
    "fold_datasets = []\n",
    "for fold in range(n_folds):\n",
    "    dataset = prepare_dataset(\n",
    "        df=df_proteins[df_proteins[\"fold\"] == fold + 1],\n",
    "        vocab=vocab,\n",
    "        max_len=max_seq_len,\n",
    "    )\n",
    "    fold_datasets.append(dataset)\n",
    "\n",
    "# check the number of samples in each fold\n",
    "for i, fold_data in enumerate(fold_datasets):\n",
    "    print(f\"Fold {i}: {len(fold_data)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: 556\n",
      "X: [18, 7, 4, 11, 21, 2, 13, 11, 2, 6, 11, 3, 11, 13, 16, 4, 5, 15, 9, 2, 3, 6, 8, 2, 7, 12, 10, 3, 6, 8]\n",
      "Y shape: (556,)\n",
      "Y: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 1. 1. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# check sample in the dataset with min sequence length\n",
    "fold1_dataset = fold_datasets[0]\n",
    "X_i, y_i = fold1_dataset[0]\n",
    "print(\"X shape:\", len(X_i))\n",
    "print(\"X:\", X_i[:30])\n",
    "print(\"Y shape:\", y_i.shape)\n",
    "print(\"Y:\", y_i[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = max_seq_len\n",
    "\n",
    "\n",
    "def collate_batch(batch):\n",
    "    # create inputs, offsets, labels for batch\n",
    "    sentences, labels = list(zip(*batch))\n",
    "    encoded_sentences = [\n",
    "        (\n",
    "            sentence + ([0] * (seq_length - len(sentence)))\n",
    "            if len(sentence) < seq_length\n",
    "            else sentence[:seq_length]\n",
    "        )\n",
    "        for sentence in sentences\n",
    "    ]\n",
    "\n",
    "    encoded_sentences = torch.tensor(encoded_sentences, dtype=torch.int64)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    return encoded_sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    fold_datasets[0], batch_size=batch_size, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    fold_datasets[1], batch_size=batch_size, shuffle=False, collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    fold_datasets[2], batch_size=batch_size, shuffle=False, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded sentences shape: torch.Size([128, 556])\n",
      "Labels shape: torch.Size([128, 556])\n"
     ]
    }
   ],
   "source": [
    "encoded_sentences, labels = next(iter(train_dataloader))\n",
    "print(\"Encoded sentences shape:\", encoded_sentences.shape)\n",
    "print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNEpitopeModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size=21,\n",
    "        embedding_dim=4,\n",
    "        hidden_size=3,\n",
    "        activation=\"relu\",\n",
    "        num_classes=2,\n",
    "    ):\n",
    "        super(RNNEpitopeModel, self).__init__()\n",
    "\n",
    "        # define embedding layers\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding_layer = nn.Embedding(\n",
    "            num_embeddings=vocab_size, embedding_dim=embedding_dim\n",
    "        )\n",
    "\n",
    "        # define RNN layer\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=self.embedding_dim,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=1,\n",
    "            nonlinearity=activation,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(self.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, X_batch):\n",
    "        embeddings = self.embedding_layer(X_batch)\n",
    "        rnn_output, _ = self.rnn(embeddings)\n",
    "        logits = self.fc(rnn_output)\n",
    "        output = F.sigmoid(logits)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RNNEpitopeModel(\n",
       "  (embedding_layer): Embedding(24, 4)\n",
       "  (rnn): RNN(4, 3, batch_first=True)\n",
       "  (fc): Linear(in_features=3, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNEpitopeModel(vocab_size=len(vocab))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 556, 2])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_sentences = encoded_sentences.to(device)\n",
    "predictions = model(encoded_sentences.to(device))\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model, optimizer, criterion, train_dataloader, device, epoch=0, log_interval=50\n",
    "):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    losses = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(inputs)\n",
    "        print(predictions.shape)\n",
    "        print(labels.shape)\n",
    "\n",
    "        # compute loss\n",
    "        loss = criterion(predictions, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "        total_count += labels.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
    "                \"| accuracy {:8.3f}\".format(\n",
    "                    epoch, idx, len(train_dataloader), total_acc / total_count\n",
    "                )\n",
    "            )\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "    epoch_acc = total_acc / total_count\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "    return epoch_acc, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_epoch(model, criterion, valid_dataloader, device):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(valid_dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            predictions = model(inputs)\n",
    "\n",
    "            loss = criterion(predictions, labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            total_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "            total_count += labels.size(0)\n",
    "\n",
    "    epoch_acc = total_acc / total_count\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "    return epoch_acc, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    model_name,\n",
    "    save_model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    train_dataloader,\n",
    "    valid_dataloader,\n",
    "    num_epochs,\n",
    "    device,\n",
    "):\n",
    "    train_accs, train_losses = [], []\n",
    "    eval_accs, eval_losses = [], []\n",
    "    best_loss_eval = 100\n",
    "    times = []\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        # Training\n",
    "        train_acc, train_loss = train_epoch(\n",
    "            model, optimizer, criterion, train_dataloader, device, epoch\n",
    "        )\n",
    "        train_accs.append(train_acc)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Evaluation\n",
    "        eval_acc, eval_loss = evaluate_epoch(model, criterion, valid_dataloader, device)\n",
    "        eval_accs.append(eval_acc)\n",
    "        eval_losses.append(eval_loss)\n",
    "\n",
    "        # Save best model\n",
    "        if eval_loss < best_loss_eval:\n",
    "            torch.save(model.state_dict(), save_model + f\"/{model_name}.pt\")\n",
    "\n",
    "        times.append(time.time() - epoch_start_time)\n",
    "        # Print loss, acc end epoch\n",
    "        print(\"-\" * 59)\n",
    "        print(\n",
    "            \"| End of epoch {:3d} | Time: {:5.2f}s | Train Accuracy {:8.3f} | Train Loss {:8.3f} \"\n",
    "            \"| Valid Accuracy {:8.3f} | Valid Loss {:8.3f} \".format(\n",
    "                epoch,\n",
    "                time.time() - epoch_start_time,\n",
    "                train_acc,\n",
    "                train_loss,\n",
    "                eval_acc,\n",
    "                eval_loss,\n",
    "            )\n",
    "        )\n",
    "        print(\"-\" * 59)\n",
    "\n",
    "    # Load best model\n",
    "    model.load_state_dict(\n",
    "        torch.load(save_model + f\"/{model_name}.pt\", weights_only=True)\n",
    "    )\n",
    "    model.eval()\n",
    "    metrics = {\n",
    "        \"train_accuracy\": train_accs,\n",
    "        \"train_loss\": train_losses,\n",
    "        \"valid_accuracy\": eval_accs,\n",
    "        \"valid_loss\": eval_losses,\n",
    "        \"time\": times,\n",
    "    }\n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_result(num_epochs, train_accs, eval_accs, train_losses, eval_losses):\n",
    "    epochs = list(range(num_epochs))\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "    axs[0].plot(epochs, train_accs, label=\"Training\")\n",
    "    axs[0].plot(epochs, eval_accs, label=\"Evaluation\")\n",
    "    axs[1].plot(epochs, train_losses, label=\"Training\")\n",
    "    axs[1].plot(epochs, eval_losses, label=\"Evaluation\")\n",
    "    axs[0].set_xlabel(\"Epochs\")\n",
    "    axs[1].set_xlabel(\"Epochs\")\n",
    "    axs[0].set_ylabel(\"Accuracy\")\n",
    "    axs[1].set_ylabel(\"Loss\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}\")\n",
    "\n",
    "model = RNNEpitopeModel(vocab_size=len(vocab))\n",
    "model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "num_epochs = 50\n",
    "save_model = \"./model\"\n",
    "os.makedirs(save_model, exist_ok=True)\n",
    "model_name = \"model\"\n",
    "\n",
    "model, metrics = train(\n",
    "    model,\n",
    "    model_name,\n",
    "    save_model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    train_dataloader,\n",
    "    valid_dataloader,\n",
    "    num_epochs,\n",
    "    device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIMA05",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
